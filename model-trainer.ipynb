{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-21T09:05:29.376020Z","iopub.execute_input":"2022-03-21T09:05:29.376882Z","iopub.status.idle":"2022-03-21T09:05:29.410133Z","shell.execute_reply.started":"2022-03-21T09:05:29.376783Z","shell.execute_reply":"2022-03-21T09:05:29.409322Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/processed-text-data/data_res.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install datasets transformers[sentencepiece]\n!pip install nltk\n!pip install rouge_score\n!apt install git-lfs\n!pip install huggingface_hub\n!pip install GPUtil","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:05:32.503228Z","iopub.execute_input":"2022-03-21T09:05:32.503783Z","iopub.status.idle":"2022-03-21T09:06:21.678040Z","shell.execute_reply.started":"2022-03-21T09:05:32.503746Z","shell.execute_reply":"2022-03-21T09:06:21.677202Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting datasets\n  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n     |████████████████████████████████| 325 kB 596 kB/s            \n\u001b[?25hRequirement already satisfied: transformers[sentencepiece] in /opt/conda/lib/python3.7/site-packages (4.15.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.26.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.2.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.2)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.62.3)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.2.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.20.3)\nCollecting xxhash\n  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n     |████████████████████████████████| 212 kB 9.1 MB/s            \n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\nCollecting responses<0.19\n  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.10.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (6.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.0.47)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.4.2)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.19.1)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.1.96)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.1)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.7)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers[sentencepiece]) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers[sentencepiece]) (8.0.3)\nInstalling collected packages: xxhash, responses, datasets\nSuccessfully installed datasets-2.0.0 responses-0.18.0 xxhash-3.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting rouge_score\n  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.20.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge_score) (0.15.0)\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.0.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following NEW packages will be installed:\n  git-lfs\n0 upgraded, 1 newly installed, 0 to remove and 58 not upgraded.\nNeed to get 3316 kB of archives.\nAfter this operation, 11.1 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\nFetched 3316 kB in 0s (15.2 MB/s)\u001b[0m\u001b[33m\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\n(Reading database ... 103273 files and directories currently installed.)\nPreparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (2.9.2-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (2.9.2-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.7/site-packages (0.2.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (2.26.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (6.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.1.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.11.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (4.62.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface_hub) (3.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface_hub) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface_hub) (3.6.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (3.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface_hub) (2.0.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting GPUtil\n  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: GPUtil\n  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=76b656c3c4f1ec9fbf24bd173e6b34847ff46671287b5c364db7ebc934379c6b\n  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\nSuccessfully built GPUtil\nInstalling collected packages: GPUtil\nSuccessfully installed GPUtil-1.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/input/processed-text-data/data_res.csv\"\n\nfrom datasets import load_dataset\n\ncv_data = load_dataset('csv',data_files = path)\n\ncv_data_clean = cv_data[\"train\"].train_test_split(train_size=0.8, seed=42)\n\ncv_data_clean[\"validation\"] = cv_data_clean.pop(\"test\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:06:25.343852Z","iopub.execute_input":"2022-03-21T09:06:25.344506Z","iopub.status.idle":"2022-03-21T09:06:27.842374Z","shell.execute_reply.started":"2022-03-21T09:06:25.344465Z","shell.execute_reply":"2022-03-21T09:06:27.841669Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-46a30972408bedde/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e07dd83fc7f345f28fb19ec1f70db215"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df1fe79305814719b8f986141c653b60"}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-46a30972408bedde/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de80d68df0bd406584358be04787a001"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n\nmodel_checkpoint = 'Ameer05/tokenizer-repo'\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:06:32.193507Z","iopub.execute_input":"2022-03-21T09:06:32.193785Z","iopub.status.idle":"2022-03-21T09:07:35.386244Z","shell.execute_reply.started":"2022-03-21T09:06:32.193753Z","shell.execute_reply":"2022-03-21T09:07:35.385371Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e54caa6538143429e1d4508ca8d7077"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/330k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb97913d6c742008a59aba0549dab61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/194k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c5ed88d96af42e7ac0ab0bcc8a4d1cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/879k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e728c6269d044d658b11d9171a4bb36d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72c5a5f6325d47da875da097014f54dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764bf9f0a24d424b85cb6dacf87226b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.51G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c37ae4e54de244ff967ec011520fe8f9"}},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 1024\nmax_target_length = 250\n\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"content\"], max_length=max_input_length, truncation=True)\n    \n    # Set up the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"target\"], max_length=max_target_length, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:07:46.204509Z","iopub.execute_input":"2022-03-21T09:07:46.204797Z","iopub.status.idle":"2022-03-21T09:07:46.210365Z","shell.execute_reply.started":"2022-03-21T09:07:46.204766Z","shell.execute_reply":"2022-03-21T09:07:46.209603Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = cv_data_clean.map(preprocess_function, batched=True)\n\ntokenized_datasets = tokenized_datasets.remove_columns(['Unnamed: 0','content','target'])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:07:49.653729Z","iopub.execute_input":"2022-03-21T09:07:49.654581Z","iopub.status.idle":"2022-03-21T09:07:50.209820Z","shell.execute_reply.started":"2022-03-21T09:07:49.654540Z","shell.execute_reply":"2022-03-21T09:07:50.209169Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1513509f7554789b1f02b0740ddb154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0ffa54615fd4660814a421d6d065728"}},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:07:52.823418Z","iopub.execute_input":"2022-03-21T09:07:52.823696Z","iopub.status.idle":"2022-03-21T09:07:52.908105Z","shell.execute_reply.started":"2022-03-21T09:07:52.823647Z","shell.execute_reply":"2022-03-21T09:07:52.907430Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center>\\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e41b954ad0e447298125404f70791042"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:08:16.964282Z","iopub.execute_input":"2022-03-21T09:08:16.964582Z","iopub.status.idle":"2022-03-21T09:08:21.731218Z","shell.execute_reply.started":"2022-03-21T09:08:16.964544Z","shell.execute_reply":"2022-03-21T09:08:21.730415Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:08:27.224352Z","iopub.execute_input":"2022-03-21T09:08:27.224618Z","iopub.status.idle":"2022-03-21T09:08:32.372893Z","shell.execute_reply.started":"2022-03-21T09:08:27.224585Z","shell.execute_reply":"2022-03-21T09:08:32.372087Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\n\nfrom datasets import load_metric\n\nrouge_score = load_metric(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:08:37.204115Z","iopub.execute_input":"2022-03-21T09:08:37.204691Z","iopub.status.idle":"2022-03-21T09:08:38.621514Z","shell.execute_reply.started":"2022-03-21T09:08:37.204637Z","shell.execute_reply":"2022-03-21T09:08:38.620865Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0d34982a7842e3880c60c24af558c7"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\nbatch_size = 8\nnum_train_epochs = 10\n# Show the training loss with every epoch\nlogging_steps = len(tokenized_datasets[\"train\"]) // batch_size\nmodel_name = model_checkpoint.split(\"/\")[-1]\n\nargs = Seq2SeqTrainingArguments(\n    output_dir=\"test\",    \n    evaluation_strategy=\"epoch\",\n    learning_rate=5e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    gradient_accumulation_steps=4,\n    fp16=True,\n    no_cuda=False,\n    gradient_checkpointing = True,\n    predict_with_generate=True,\n    num_train_epochs=num_train_epochs,\n    push_to_hub  = True,\n    logging_steps=logging_steps,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:08:46.963354Z","iopub.execute_input":"2022-03-21T09:08:46.963613Z","iopub.status.idle":"2022-03-21T09:08:46.991384Z","shell.execute_reply.started":"2022-03-21T09:08:46.963583Z","shell.execute_reply":"2022-03-21T09:08:46.990658Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    # Decode generated summaries into text\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    # Decode reference summaries into text\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    # ROUGE expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n    # Compute ROUGE scores\n    result = rouge_score.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    # Extract the median scores\n    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:08:52.474465Z","iopub.execute_input":"2022-03-21T09:08:52.475356Z","iopub.status.idle":"2022-03-21T09:08:52.483297Z","shell.execute_reply.started":"2022-03-21T09:08:52.475287Z","shell.execute_reply":"2022-03-21T09:08:52.482488Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:08:57.511141Z","iopub.execute_input":"2022-03-21T09:08:57.512027Z","iopub.status.idle":"2022-03-21T09:10:06.951034Z","shell.execute_reply.started":"2022-03-21T09:08:57.511989Z","shell.execute_reply":"2022-03-21T09:10:06.950106Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"Cloning https://huggingface.co/Ameer05/test into local empty directory.\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"Using amp half precision backend\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"True\"","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:10:10.553927Z","iopub.execute_input":"2022-03-21T09:10:10.554562Z","iopub.status.idle":"2022-03-21T09:10:10.558555Z","shell.execute_reply.started":"2022-03-21T09:10:10.554514Z","shell.execute_reply":"2022-03-21T09:10:10.557865Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    return gpu_usage(),torch.cuda.empty_cache()\n    \n\n    \nfree_gpu_cache()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:10:15.375477Z","iopub.execute_input":"2022-03-21T09:10:15.376169Z","iopub.status.idle":"2022-03-21T09:10:15.928743Z","shell.execute_reply.started":"2022-03-21T09:10:15.376126Z","shell.execute_reply":"2022-03-21T09:10:15.927918Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Initial GPU Usage\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n| ID | GPU | MEM |\n------------------\n|  0 |  0% | 15% |\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(None, None)"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:10:24.023893Z","iopub.execute_input":"2022-03-21T09:10:24.024217Z","iopub.status.idle":"2022-03-21T09:24:13.514573Z","shell.execute_reply.started":"2022-03-21T09:10:24.024183Z","shell.execute_reply":"2022-03-21T09:24:13.513728Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 176\n  Num Epochs = 10\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 4\n  Total optimization steps = 50\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to `offline` in this directory.  <br/>\nRun `wandb online` or set WANDB_MODE=online to enable cloud syncing."},"metadata":{}},{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n/opt/conda/lib/python3.7/site-packages/transformers/trainer.py:1373: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n  args.max_grad_norm,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 13:32, Epoch 9/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>2.370505</td>\n      <td>53.620000</td>\n      <td>44.383500</td>\n      <td>49.613500</td>\n      <td>52.693000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.903546</td>\n      <td>47.478000</td>\n      <td>37.093400</td>\n      <td>39.793500</td>\n      <td>45.188100</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.799004</td>\n      <td>54.248800</td>\n      <td>45.078200</td>\n      <td>49.842100</td>\n      <td>52.756400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.712547</td>\n      <td>55.790300</td>\n      <td>46.755400</td>\n      <td>52.273300</td>\n      <td>54.938900</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.445600</td>\n      <td>1.642136</td>\n      <td>52.227900</td>\n      <td>43.439100</td>\n      <td>49.695500</td>\n      <td>51.291500</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.445600</td>\n      <td>1.610172</td>\n      <td>55.859800</td>\n      <td>47.329300</td>\n      <td>53.133700</td>\n      <td>54.859600</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.445600</td>\n      <td>1.616433</td>\n      <td>53.790200</td>\n      <td>44.662200</td>\n      <td>49.504500</td>\n      <td>52.230400</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.445600</td>\n      <td>1.601482</td>\n      <td>51.559700</td>\n      <td>42.033300</td>\n      <td>47.963900</td>\n      <td>50.115400</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.239000</td>\n      <td>1.606690</td>\n      <td>53.030100</td>\n      <td>43.721400</td>\n      <td>49.022700</td>\n      <td>51.810900</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.239000</td>\n      <td>1.610872</td>\n      <td>54.944200</td>\n      <td>45.329900</td>\n      <td>50.521900</td>\n      <td>53.647500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=50, training_loss=1.7401448249816895, metrics={'train_runtime': 829.4455, 'train_samples_per_second': 2.122, 'train_steps_per_second': 0.06, 'total_flos': 3591247866298368.0, 'train_loss': 1.7401448249816895, 'epoch': 9.91})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:30:50.464054Z","iopub.execute_input":"2022-03-21T09:30:50.464346Z","iopub.status.idle":"2022-03-21T09:31:13.768780Z","shell.execute_reply.started":"2022-03-21T09:30:50.464315Z","shell.execute_reply":"2022-03-21T09:31:13.767982Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 44\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6/6 00:18]\n    </div>\n    "},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.6108719110488892,\n 'eval_rouge1': 54.9442,\n 'eval_rouge2': 45.3299,\n 'eval_rougeL': 50.5219,\n 'eval_rougeLsum': 53.6475,\n 'eval_runtime': 23.278,\n 'eval_samples_per_second': 1.89,\n 'eval_steps_per_second': 0.258,\n 'epoch': 9.91}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T09:31:13.774979Z","iopub.execute_input":"2022-03-21T09:31:13.778085Z","iopub.status.idle":"2022-03-21T09:35:07.580109Z","shell.execute_reply.started":"2022-03-21T09:31:13.778039Z","shell.execute_reply":"2022-03-21T09:35:07.579192Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Saving model checkpoint to test\nConfiguration saved in test/config.json\nModel weights saved in test/pytorch_model.bin\ntokenizer config file saved in test/tokenizer_config.json\nSpecial tokens file saved in test/special_tokens_map.json\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload file pytorch_model.bin:   0%|          | 32.0k/1.51G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ccff8f32ecc4512afdf477808118ec3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload file training_args.bin: 100%|##########| 2.98k/2.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af9a31ef20f41a19959e23a8a3b5287"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload file runs/Mar21_09-08-46_60bccfd992b0/events.out.tfevents.1647853824.60bccfd992b0.33.0: 100%|##########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c20d74fde8c4a81888c79d89d98d115"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload file runs/Mar21_09-08-46_60bccfd992b0/events.out.tfevents.1647855073.60bccfd992b0.33.2: 100%|##########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44088ee1d0544984bd9ceb01b21e6840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload file runs/Mar21_09-08-46_60bccfd992b0/1647853824.0908887/events.out.tfevents.1647853824.60bccfd992b0.33…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81fdf19b764c43c48648441e29748af0"}},"metadata":{}},{"name":"stderr","text":"remote: tput: No value for $TERM and no -T specified        \nremote: tput: No value for $TERM and no -T specified\nremote: tput: No value for $TERM and no -T specified        \nremote: tput: No value for $TERM and no -T specified        \nTo https://huggingface.co/Ameer05/test\n   7732d54..8befc4c  main -> main\n\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"Dropping the following result as it does not have all the necessary fields:\n{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 54.9442}]}\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"remote: tput: No value for $TERM and no -T specified        \nremote: tput: No value for $TERM and no -T specified        \nremote: tput: No value for $TERM and no -T specified        \nremote: tput: No value for $TERM and no -T specified        \nTo https://huggingface.co/Ameer05/test\n   8befc4c..d146ed6  main -> main\n\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/Ameer05/test/commit/8befc4cc3652d2e7977201282d7de32cef7152e5'"},"metadata":{}}]}]}